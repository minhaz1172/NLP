{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdXl+7/Dujtlzy0uGlm8DT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhaz1172/NLP/blob/main/Count_Vectorizer(python).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CountVectorizer in NLP\n",
        "\n",
        "`CountVectorizer` is a tool in Python's **scikit-learn** library used to convert a collection of text documents into a matrix of token counts. It essentially creates a **Bag of Words (BoW)** representation, where each unique word becomes a feature, and the value for each document-feature pair is the frequency of that word in the document.\n",
        "\n",
        "This process transforms text data into a numerical format that can be used by machine learning models.\n",
        "\n",
        "---\n",
        "\n",
        "## What CountVectorizer Does\n",
        "\n",
        "- **Tokenization:**  \n",
        "  `CountVectorizer` breaks down text into individual words or tokens.\n",
        "  \n",
        "- **Vocabulary Building:**  \n",
        "  It identifies all the unique words (or tokens) across the entire text corpus.\n",
        "  \n",
        "- **Counting:**  \n",
        "  For each document, it counts how many times each unique word appears.\n",
        "  \n",
        "- **Matrix Creation:**  \n",
        "  It organizes these counts into a matrix where:\n",
        "  - Rows represent documents.\n",
        "  - Columns represent unique words.\n",
        "  - Cells contain the word counts.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Use CountVectorizer?\n",
        "\n",
        "- **Text as Input:**  \n",
        "  Machine learning models generally require numerical input. `CountVectorizer` converts text into a numerical format that models can understand.\n",
        "\n",
        "- **Feature Extraction:**  \n",
        "  It identifies and quantifies the frequency of words, allowing you to extract meaningful features from text data.\n",
        "\n",
        "- **Efficiency:**  \n",
        "  `scikit-learn`'s implementation is optimized for performance, especially when dealing with large datasets.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "AeapTenjbBKh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FNNpNEvlaj3a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "Text=['My name is Minhaz.',\n",
        "      'I am an Engineering student.',\n",
        "      'And I am studying at RUET.',\n",
        "      'Minhaz is practicing ML.']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a object for count vectorizer\n",
        "vectorizer=CountVectorizer()"
      ],
      "metadata": {
        "id": "8NAj9cvQcBJi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and transform the corpus\n",
        "X=vectorizer.fit_transform(Text)"
      ],
      "metadata": {
        "id": "Kpt-2lzvcGxH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the feature names\n",
        "feature_names=vectorizer.get_feature_names_out()\n",
        "feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjASrLHdcQ5e",
        "outputId": "78d8fbae-e4b0-43c2-c7eb-f6f73c02fb7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['am', 'an', 'and', 'at', 'engineering', 'i', 'is', 'minhaz', 'ml',\n",
              "       'my', 'name', 'practicing', 'ruet', 'student', 'studying'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# the single word 'I' is missing from the get_feature_names_out() output is because by default, CountVectorizer ignores all tokens (words) that are only one character long."
      ],
      "metadata": {
        "id": "kMQ3eQKddcYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Include also single word like I'\n",
        "vectorizer=CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "X=vectorizer.fit_transform(Text)\n",
        "feature_names=vectorizer.get_feature_names_out()\n",
        "feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN_rgPQHdgRz",
        "outputId": "8cf5b83b-80f2-4ca1-c7fb-a9543a24be16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['am', 'an', 'and', 'at', 'engineering', 'i', 'is', 'minhaz', 'ml',\n",
              "       'my', 'name', 'practicing', 'ruet', 'student', 'studying'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy arrays donâ€™t have the toarray() method.X is a sparse matrix"
      ],
      "metadata": {
        "id": "PxbzncKPfOkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import issparse\n",
        "\n",
        "if issparse(X):\n",
        "    print(f\"X = {X.toarray()}\")\n",
        "else:\n",
        "    print(f\"X = {X}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcR72TdteJ86",
        "outputId": "0899618a-c4c8-48db-900f-b8aa14dc0ef7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = [[0 0 0 0 0 0 1 1 0 1 1 0 0 0 0]\n",
            " [1 1 0 0 1 1 0 0 0 0 0 0 0 1 0]\n",
            " [1 0 1 1 0 1 0 0 0 0 0 0 1 0 1]\n",
            " [0 0 0 0 0 0 1 1 1 0 0 1 0 0 0]]\n"
          ]
        }
      ]
    }
  ]
}