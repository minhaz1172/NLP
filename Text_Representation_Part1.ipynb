{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1qbTAbWYperaq6m148+bc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhaz1172/NLP/blob/main/Text_Representation_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "text data needs to be converted into numbers so that machine learning algorithms can understand it. One common method to do this is Bag of Words (BoW) model. It turns text like sentence, paragraph or document into a collection of words and counts how often each word appears but ignoring the order of the words."
      ],
      "metadata": {
        "id": "09LXM4V4v0kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Corpus** → Collection of many documents  \n",
        "- **Document** → A single piece of text (sentence, paragraph, article, etc.)  \n",
        "- **Vocabulary** → Unique set of words across all documents  \n",
        "- **Word (Token)** → Individual element inside a document  \n"
      ],
      "metadata": {
        "id": "KO2Xof3LLl24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Techniques-1:Using Python"
      ],
      "metadata": {
        "id": "0rN8zpicem0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step-1:Preprocess data"
      ],
      "metadata": {
        "id": "A8WYTtPeexSh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXmHNAHZAqMv"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import string\n",
        "\n",
        "text=\"\"\"Beans. I was trying to explain to somebody as we were flying in, that's corn.  That's beans. And they were very impressed at my agricultural knowledge. Please give it up for Amaury once again for that outstanding introduction. I have a bunch of good friends here today, including somebody who I served with, who is one of the finest senators in the country, and we're lucky to have him, your Senator, Dick Durbin is here. I also noticed, by the way, former Governor Edgar here, who I haven't seen in a long time, and somehow he has not aged and I have. And it's great to see you, Governor. \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw35Q6HcLkje",
        "outputId": "52c6f6db-9ab1-4107-fc23-8b0322baec8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=nltk.sent_tokenize(text)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf4FW_o_gbdM",
        "outputId": "a6aa8755-3b51-4173-b3bf-9ea0317ef5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Beans.',\n",
              " \"I was trying to explain to somebody as we were flying in, that's corn.\",\n",
              " \"That's beans.\",\n",
              " 'And they were very impressed at my agricultural knowledge.',\n",
              " 'Please give it up for Amaury once again for that outstanding introduction.',\n",
              " \"I have a bunch of good friends here today, including somebody who I served with, who is one of the finest senators in the country, and we're lucky to have him, your Senator, Dick Durbin is here.\",\n",
              " \"I also noticed, by the way, former Governor Edgar here, who I haven't seen in a long time, and somehow he has not aged and I have.\",\n",
              " \"And it's great to see you, Governor.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "# lowering text\n",
        "text=text.lower()\n",
        "# remove punctuation\n",
        "text=text.translate(str.maketrans('','',string.punctuation))\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw1j521jfbsu",
        "outputId": "77af6f5d-6bd1-4e90-9ba3-7ec447ab1bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['beans',\n",
              " 'i was trying to explain to somebody as we were flying in thats corn',\n",
              " 'thats beans',\n",
              " 'and they were very impressed at my agricultural knowledge',\n",
              " 'please give it up for amaury once again for that outstanding introduction',\n",
              " 'i have a bunch of good friends here today including somebody who i served with who is one of the finest senators in the country and were lucky to have him your senator dick durbin is here',\n",
              " 'i also noticed by the way former governor edgar here who i havent seen in a long time and somehow he has not aged and i have',\n",
              " 'and its great to see you governor']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "# lowering text\n",
        "preprocessed_text=[]\n",
        "\n",
        "for sentence in text:\n",
        "  sentence=sentence.lower()\n",
        "  sentence=sentence.translate(str.maketrans('','',string.punctuation))\n",
        "  preprocessed_text.append(sentence)\n",
        "\n",
        "text=preprocessed_text\n",
        "text\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nny6BXkOgpqQ",
        "outputId": "3a8a1093-4c3c-4d72-af0b-05ab83763db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['beans',\n",
              " 'i was trying to explain to somebody as we were flying in thats corn',\n",
              " 'thats beans',\n",
              " 'and they were very impressed at my agricultural knowledge',\n",
              " 'please give it up for amaury once again for that outstanding introduction',\n",
              " 'i have a bunch of good friends here today including somebody who i served with who is one of the finest senators in the country and were lucky to have him your senator dick durbin is here',\n",
              " 'i also noticed by the way former governor edgar here who i havent seen in a long time and somehow he has not aged and i have',\n",
              " 'and its great to see you governor']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Tokenization"
      ],
      "metadata": {
        "id": "R-GmTGURhhEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Word tokenization\n",
        "tokenized_text = []\n",
        "for sentence in text:\n",
        "    tokenized_text.append(nltk.word_tokenize(sentence))\n",
        "\n",
        "text = tokenized_text\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOlOjrB9hjOJ",
        "outputId": "bef20163-d37e-4bd7-9935-7e8b1e9ee379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['beans'],\n",
              " ['i',\n",
              "  'was',\n",
              "  'trying',\n",
              "  'to',\n",
              "  'explain',\n",
              "  'to',\n",
              "  'somebody',\n",
              "  'as',\n",
              "  'we',\n",
              "  'were',\n",
              "  'flying',\n",
              "  'in',\n",
              "  'thats',\n",
              "  'corn'],\n",
              " ['thats', 'beans'],\n",
              " ['and',\n",
              "  'they',\n",
              "  'were',\n",
              "  'very',\n",
              "  'impressed',\n",
              "  'at',\n",
              "  'my',\n",
              "  'agricultural',\n",
              "  'knowledge'],\n",
              " ['please',\n",
              "  'give',\n",
              "  'it',\n",
              "  'up',\n",
              "  'for',\n",
              "  'amaury',\n",
              "  'once',\n",
              "  'again',\n",
              "  'for',\n",
              "  'that',\n",
              "  'outstanding',\n",
              "  'introduction'],\n",
              " ['i',\n",
              "  'have',\n",
              "  'a',\n",
              "  'bunch',\n",
              "  'of',\n",
              "  'good',\n",
              "  'friends',\n",
              "  'here',\n",
              "  'today',\n",
              "  'including',\n",
              "  'somebody',\n",
              "  'who',\n",
              "  'i',\n",
              "  'served',\n",
              "  'with',\n",
              "  'who',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'finest',\n",
              "  'senators',\n",
              "  'in',\n",
              "  'the',\n",
              "  'country',\n",
              "  'and',\n",
              "  'were',\n",
              "  'lucky',\n",
              "  'to',\n",
              "  'have',\n",
              "  'him',\n",
              "  'your',\n",
              "  'senator',\n",
              "  'dick',\n",
              "  'durbin',\n",
              "  'is',\n",
              "  'here'],\n",
              " ['i',\n",
              "  'also',\n",
              "  'noticed',\n",
              "  'by',\n",
              "  'the',\n",
              "  'way',\n",
              "  'former',\n",
              "  'governor',\n",
              "  'edgar',\n",
              "  'here',\n",
              "  'who',\n",
              "  'i',\n",
              "  'havent',\n",
              "  'seen',\n",
              "  'in',\n",
              "  'a',\n",
              "  'long',\n",
              "  'time',\n",
              "  'and',\n",
              "  'somehow',\n",
              "  'he',\n",
              "  'has',\n",
              "  'not',\n",
              "  'aged',\n",
              "  'and',\n",
              "  'i',\n",
              "  'have'],\n",
              " ['and', 'its', 'great', 'to', 'see', 'you', 'governor']]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Vocabulary"
      ],
      "metadata": {
        "id": "UbJvilYJhyFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize an empty set for vocsbulary\n",
        "vocabulary=set()\n",
        "\n",
        "# build the vocabulary\n",
        "for word in text:\n",
        "  vocabulary.update(word)\n",
        "\n",
        "  # conver to a sorted list\n",
        "\n",
        "vocabulary=sorted(list(vocabulary))\n",
        "vocabulary"
      ],
      "metadata": {
        "id": "nVf6w8Wxh0r_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09430424-fc7f-4ab5-d4ba-7b95e536ca5d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'again',\n",
              " 'aged',\n",
              " 'agricultural',\n",
              " 'also',\n",
              " 'amaury',\n",
              " 'and',\n",
              " 'as',\n",
              " 'at',\n",
              " 'beans',\n",
              " 'bunch',\n",
              " 'by',\n",
              " 'corn',\n",
              " 'country',\n",
              " 'dick',\n",
              " 'durbin',\n",
              " 'edgar',\n",
              " 'explain',\n",
              " 'finest',\n",
              " 'flying',\n",
              " 'for',\n",
              " 'former',\n",
              " 'friends',\n",
              " 'give',\n",
              " 'good',\n",
              " 'governor',\n",
              " 'great',\n",
              " 'has',\n",
              " 'have',\n",
              " 'havent',\n",
              " 'he',\n",
              " 'here',\n",
              " 'him',\n",
              " 'i',\n",
              " 'impressed',\n",
              " 'in',\n",
              " 'including',\n",
              " 'introduction',\n",
              " 'is',\n",
              " 'it',\n",
              " 'its',\n",
              " 'knowledge',\n",
              " 'long',\n",
              " 'lucky',\n",
              " 'my',\n",
              " 'not',\n",
              " 'noticed',\n",
              " 'of',\n",
              " 'once',\n",
              " 'one',\n",
              " 'outstanding',\n",
              " 'please',\n",
              " 'see',\n",
              " 'seen',\n",
              " 'senator',\n",
              " 'senators',\n",
              " 'served',\n",
              " 'somebody',\n",
              " 'somehow',\n",
              " 'that',\n",
              " 'thats',\n",
              " 'the',\n",
              " 'they',\n",
              " 'time',\n",
              " 'to',\n",
              " 'today',\n",
              " 'trying',\n",
              " 'up',\n",
              " 'very',\n",
              " 'was',\n",
              " 'way',\n",
              " 'we',\n",
              " 'were',\n",
              " 'who',\n",
              " 'with',\n",
              " 'you',\n",
              " 'your']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# calculate word frequencies and vectorize\n"
      ],
      "metadata": {
        "id": "SgYZyCcCtfPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bow_vector(sentence,vocab):\n",
        "  vector=[0]* len(vocab) # initialize a vector of zeros\n",
        "\n",
        "  for word in sentence:\n",
        "    if word in vocab:\n",
        "      idx=vocab.index(word) # find the index of word in voabulary\n",
        "      vector[idx]+=1 # increment the count at theat index\n",
        "\n",
        "  return vector\n"
      ],
      "metadata": {
        "id": "Abfp5pSetmqE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vectors=[create_bow_vector(sentence,vocabulary) for sentence in text]\n",
        "print(\"Bag of Words in Vectors:\")\n",
        "for vector in bow_vectors:\n",
        "  print(vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a0hwLSmuWof",
        "outputId": "178a474d-be43-4ab8-aa82-c1e676d355f8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words in Vectors:\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 2, 0, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1]\n",
            "[1, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2nd Techniques is CounterVectrizer Scikit learn technique which already done"
      ],
      "metadata": {
        "id": "kW8l0ukzvj8s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u5W371DPvqzg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}